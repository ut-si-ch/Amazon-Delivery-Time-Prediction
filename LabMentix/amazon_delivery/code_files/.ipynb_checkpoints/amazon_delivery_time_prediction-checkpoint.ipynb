{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Styling of CodeBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* For JupyterLab markdown outputs */\n",
       ".jp-MarkdownOutput {\n",
       "    background-color: #232f3e !important;\n",
       "    color: #e47911 !important;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px;\n",
       "    font-size: 16px;\n",
       "    line-height: 1.6;\n",
       "    font-family: \"Amazon Ember\", Arial, sans-serif;\n",
       "}\n",
       "\n",
       "/* Headings */\n",
       ".jp-MarkdownOutput h1, \n",
       ".jp-MarkdownOutput h2, \n",
       ".jp-MarkdownOutput h3 {\n",
       "    color: #ff9900 !important;\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       "/* Links */\n",
       ".jp-MarkdownOutput a {\n",
       "    color: #ff9900 !important;\n",
       "    font-weight: bold;\n",
       "    text-decoration: none;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* For JupyterLab markdown outputs */\n",
    ".jp-MarkdownOutput {\n",
    "    background-color: #232f3e !important;\n",
    "    color: #e47911 !important;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    font-size: 16px;\n",
    "    line-height: 1.6;\n",
    "    font-family: \"Amazon Ember\", Arial, sans-serif;\n",
    "}\n",
    "\n",
    "/* Headings */\n",
    ".jp-MarkdownOutput h1, \n",
    ".jp-MarkdownOutput h2, \n",
    ".jp-MarkdownOutput h3 {\n",
    "    color: #ff9900 !important;\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    "/* Links */\n",
    ".jp-MarkdownOutput a {\n",
    "    color: #ff9900 !important;\n",
    "    font-weight: bold;\n",
    "    text-decoration: none;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vncDsAP0Gaoa"
   },
   "source": [
    "# **Project Name**    -  Amazon Delivery Time Prediction 🚚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beRrZCGUAJYm"
   },
   "source": [
    "##### **Project Type**    - EDA/Regression/Prediction\n",
    "##### **Contribution**    - Individual\n",
    "##### **Team Member -** Uttam Singh Chaudhary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJNUwmbgGyua"
   },
   "source": [
    "# **Project Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project focuses on predicting Amazon Delivery Time using machine learning, with the goal of providing customers with realistic delivery estimates and enabling logistics teams to optimize operations. The workflow involved data exploration, feature engineering, multiple regression model development, experiment tracking with MLflow, and deployment of the best-performing model using a Streamlit application.\n",
    "\n",
    "The dataset consisted of order-related features such as Agent Age, Agent Rating, Store Latitude/Longitude, Drop Latitude/Longitude, Order and Pickup timestamps, Distance (KM), Time-to-Pickup, Weather conditions, Traffic intensity, Vehicle type, Delivery Area, and Product Category. Initially, the dataset had only 16 columns, but after performing one-hot encoding on categorical variables such as Weather, Traffic, Vehicle, Area, and Category, it expanded to 44 feature columns.\n",
    "\n",
    "During Exploratory Data Analysis (EDA), visualizations helped uncover patterns in the data. We plotted feature distributions, relationships between numeric variables, and correlations. Feature importance was computed using tree-based models, revealing that Category_Grocery, Agent Rating, Distance (KM), Traffic_Low, and Agent Age were the most influential predictors, with importance scores ranging between 0.05 and 0.24. This highlighted that both agent performance and logistics-related features significantly affect delivery time.\n",
    "\n",
    "In feature engineering, categorical variables were carefully handled. Although one-hot encoding expanded feature space, it prevented misleading ordinal relationships that would arise if label encoding had been applied to nominal categories (e.g., Sunny = 1, Foggy = 3). Time-based features such as Order Hour, Day, and Weekday as well as flags like Is_Weekend were derived to capture scheduling patterns. Continuous features like Distance_KM and Agent Rating were kept in numerical form for modeling.\n",
    "\n",
    "We experimented with several machine learning models including Linear Regression, Random Forest Regressor, Gradient Boosting Regressor, XGBoost, LightGBM, and CatBoost. Each model was trained and logged in MLflow, where metrics such as RMSE, MAE, and R² were tracked. MLflow’s experiment tracking feature allowed us to visualize and compare model performance across multiple runs, making the process more systematic. The ability to register models inside MLflow also provided version control and reproducibility.\n",
    "\n",
    "The results showed that ensemble models (LightGBM and XGBoost) achieved superior accuracy compared to linear methods. For example, LightGBM captured non-linear interactions effectively, while Random Forest provided interpretability through feature importance plots. Model performances were not just logged but also visualized inside the MLflow UI, helping us compare runs and decide which models to register.\n",
    "\n",
    "Once the best models were identified, they were integrated into a Streamlit application to provide an interactive interface. The app allowed users to input key features such as Agent Rating, Distance, Traffic Level, Product Category, and Weather Condition and receive an estimated delivery time in real-time. Instead of overwhelming the UI with all 44 dummy-encoded columns, only the most important and user-friendly features were exposed to the front end. This streamlined the user experience while maintaining predictive accuracy. Screenshots of the Streamlit app were also captured to document the workflow.\n",
    "\n",
    "An important design decision was that models were not saved as .h5 files. Instead, MLflow managed experiment tracking and model storage. On a local environment, models could be loaded directly from MLflow for inference. However, for deployment on cloud platforms such as Streamlit Cloud or GitHub, a main.py file and supporting scripts would be used, with either MLflow artifacts or manually saved models (in .pkl or .joblib formats) integrated depending on the deployment pipeline. This reflects a real-world scenario where companies use MLflow in conjunction with cloud orchestration tools to manage production-level models.\n",
    "\n",
    "In conclusion, this project demonstrated the complete end-to-end ML workflow for Amazon Delivery Time Prediction: from EDA and feature engineering, to model experimentation and logging with MLflow, and finally to deploying an interactive prediction system using Streamlit. The pipeline reflects industry practices where multiple models are compared, the best are registered, and user-facing applications are built to provide business value. This project not only highlights technical proficiency in machine learning and MLOps but also practical thinking in designing a recruiter-friendly, cloud-deployable solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6K7xa23Elo4"
   },
   "source": [
    "# 🚚 Amazon Delivery Time Prediction Project Links - \n",
    "GitHub Repository: [Amazon Delivery Time Prediction](https://github.com/ut-si-ch/Amazon-Delivery-Time-Prediction.git)  \n",
    "Streamlit Web App Link: [Amazon Delivery Time Prediction_Streamlit Web APP]()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQaldy8SH6Dl"
   },
   "source": [
    "##  Problem Statement\n",
    "This project aims to predict delivery times for e-commerce orders based on factors like product size, distance, traffic, weather, and shipping method.  \n",
    "The goal is to build accurate regression models and deploy a user-friendly app to estimate delivery times.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Use Cases\n",
    "- **Enhanced Logistics**: Predict delivery times → improve customer satisfaction.  \n",
    "- **Dynamic Adjustments**: Factor in real-time traffic and weather.  \n",
    "- **Agent Performance**: Evaluate efficiency and optimize training.  \n",
    "- **Operational Efficiency**: Better resource allocation and scheduling.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dataset Overview\n",
    "The dataset (`amazon_delivery.csv`) contains details like:  \n",
    "- `Order_ID`, `Agent_Age`, `Agent_Rating`  \n",
    "- `Store_Latitude/Longitude`, `Drop_Latitude/Longitude`  \n",
    "- `Order_Date`, `Order_Time`, `Pickup_Time`  \n",
    "- `Weather`, `Traffic`, `Vehicle`, `Area`, `Category`  \n",
    "- Target Variable: `Delivery_Time (hours)`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "1. **Preliminary Data Inspection**\n",
    "2. **Data Preparation & Cleaning**  \n",
    "3. **Exploratory Data Analysis (EDA)**  \n",
    "4. **Feature Engineering (distances, time-based features, etc.)**  \n",
    "5. **Regression Model Development**  \n",
    "   - Linear Regression  \n",
    "   - Random Forest  \n",
    "   - Gradient Boosting  \n",
    "6. **Model Tracking with MLflow**  \n",
    "7. **Streamlit App for Deployment**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDgbUHAGgjLW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **General Guidelines** : -  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxVaUj-hHfC"
   },
   "source": [
    "1.   Well-structured, formatted, and commented code is required.\n",
    "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
    "     \n",
    "     The additional credits will have advantages over other students during Star Student selection.\n",
    "       \n",
    "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
    "                       without a single error logged. ]\n",
    "\n",
    "3.   Each and every logic should have proper comments.\n",
    "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
    "        \n",
    "\n",
    "```\n",
    "# Chart visualization code\n",
    "```\n",
    "            \n",
    "\n",
    "*   Why did you pick the specific chart?\n",
    "*   What is/are the insight(s) found from the chart?\n",
    "* Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason.\n",
    "\n",
    "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
    "\n",
    "\n",
    "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
    "\n",
    "U - Univariate Analysis,\n",
    "\n",
    "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
    "\n",
    "M - Multivariate Analysis\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
    "\n",
    "\n",
    "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
    "\n",
    "\n",
    "*   Cross- Validation & Hyperparameter Tuning\n",
    "\n",
    "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
    "\n",
    "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_i_v8NEhb9l"
   },
   "source": [
    "# ***Let's Begin !***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhfV-JJviCcP"
   },
   "source": [
    "## ***1. Know Your Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3lxredqlCYt"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M8Vqi-pPk-HR"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model Building libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Warnings Related \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RnN4peoiCZX"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4CkvbW_SlZ_R"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/amazon_delivery.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m amazon_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../dataset/amazon_delivery.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Loaded Successfully!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\amazon_delivery\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\amazon_delivery\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\amazon_delivery\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\amazon_delivery\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\amazon_delivery\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/amazon_delivery.csv'"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "amazon_df = pd.read_csv('../dataset/amazon_delivery.csv')\n",
    "print(\"Dataset Loaded Successfully!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x71ZqKXriCWQ"
   },
   "source": [
    "### Dataset First View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWNFOSvLl09H"
   },
   "outputs": [],
   "source": [
    "# Dataset First Look\n",
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hBIi_osiCS2"
   },
   "source": [
    "### Dataset Rows & Columns count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kllu7SJgmLij"
   },
   "outputs": [],
   "source": [
    "# Dataset Rows & Columns count\n",
    "amazon_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlHwYmJAmNHm"
   },
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9hRXRi6meOf"
   },
   "outputs": [],
   "source": [
    "# Dataset Info\n",
    "amazon_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35m5QtbWiB9F"
   },
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sLdpKYkmox0"
   },
   "outputs": [],
   "source": [
    "# Dataset Duplicate Value Count\n",
    "amazon_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoPl-ycgm1ru"
   },
   "source": [
    "#### Missing Values/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgHWkxvamxVg"
   },
   "outputs": [],
   "source": [
    "# Missing Values/Null Values Count\n",
    "amazon_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q5wnI3om9sJ"
   },
   "outputs": [],
   "source": [
    "# Visualising the missing values\n",
    "missing_mask = amazon_df.isnull()\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.heatmap(missing_mask, cmap='viridis', cbar = True)\n",
    "plt.title(\"Missing Values in the Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0kj-8xxnORC"
   },
   "source": [
    "### What did you know about your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfoNAAC-nUe_"
   },
   "source": [
    "### Key Point from Preliminary Data Inspection\n",
    "1. **Shape** - **(43739, 16)** → large enough dataset, good for ML.\n",
    "2. **Missing Values** - Column = **Agent_Rating**: 54 missing; **Weather**: 91 missing; rest is complete.\n",
    "3. **Data Types**\n",
    "    - **Order_ID**: categorical ID (not useful for modeling directly).\n",
    "    - **Order_Date**, Order_Time, Pickup_Time: stored as object → should be converted to datetime.\n",
    "    - **Lat/Long** are float64 (good).\n",
    "    - Others are categorical (Weather, Traffic, Vehicle, Area, Category)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA9Y7ga8ng1Z"
   },
   "source": [
    "## ***2. Understanding Your Variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7xfkqrt5Ag5"
   },
   "outputs": [],
   "source": [
    "# Dataset Columns\n",
    "amazon_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnOaZdaE5Q5t"
   },
   "outputs": [],
   "source": [
    "# Dataset Describe\n",
    "amazon_df.describe(include = 'all').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBTbrJXOngz2"
   },
   "source": [
    "### Variables Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJV4KIxSnxay"
   },
   "source": [
    "### Key Points\n",
    "1. **Numerical Features**\n",
    "   - **Agent_Age**: range 15–50, reasonable but might check for outliers (too young/too old delivery agents?).\n",
    "   - **Agent_Rating**: mean ~4.63, but max = 6.0 → outlier (ratings usually capped at 5).\n",
    "   - **Lat/Long**: have negative and near-zero values → need validation (some invalid coordinates).\n",
    "   - **Delivery_Time**: mean ~124 min, ranges 10–270 mins (target variable for regression)\n",
    "2. **Categorical Features**\n",
    "   - **Weather**: 6 categories (Fog, Sunny, Cloudy, Stormy, Sandstorms, Rainy?).\n",
    "   - **Traffic**: 5 levels (Low, Medium, High, Jam, etc.)\n",
    "   - **Vehicle**: 4 (motorcycle, scooter, bicycle, car?)\n",
    "   - **Area**: 4 (Urban, Semi-Urban, Metropolitan, Rural).\n",
    "   - **Category**: 16 product categories (Electronics, Clothing, Sports, Cosmetics, Toys, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3PMJOP6ngxN"
   },
   "source": [
    "### Check Unique Values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zms12Yq5n-jE"
   },
   "outputs": [],
   "source": [
    "# Check Unique Values for each variable.\n",
    "for col in amazon_df.columns:\n",
    "    print(\"-\"*75)\n",
    "    print(\"Column Name: \",col)\n",
    "    print(\"Total Unique Count:- \",amazon_df[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dauF4eBmngu3"
   },
   "source": [
    "## 3. ***Data Preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKJF3rekwFvQ"
   },
   "source": [
    "### Data Preprocessing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk-9a2fpoLcV"
   },
   "outputs": [],
   "source": [
    "# Load the dataset Again to make it analysis ready\n",
    "amazon_df = pd.read_csv(\"../dataset/amazon_delivery.csv\")\n",
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the count of null values again\n",
    "amazon_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check agent_rating column\n",
    "amazon_df['Agent_Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df['Agent_Rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the 54 NaN Values with the median rating value beacuse mean values will skew the data; skew resistant\n",
    "amazon_df['Agent_Rating'].fillna(amazon_df['Agent_Rating'].median(), inplace = True)\n",
    "\n",
    "# Clip the ratings to 1-5, removing the 6.0 values, as they have only 53 instances.\n",
    "amazon_df['Agent_Rating'] = amazon_df['Agent_Rating'].clip(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the missing values in 'Weather' Column, mean and median work on numerical data, but mode works on string data as well.\n",
    "amazon_df['Weather'].fillna(amazon_df['Weather'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df['Weather'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date time columns to proper format\n",
    "amazon_df['Order_Date'] = pd.to_datetime(amazon_df['Order_Date'])\n",
    "amazon_df['Order_Time'] = pd.to_datetime(amazon_df['Order_Time'], format='%H:%M:%S', errors='coerce').dt.time    \n",
    "amazon_df['Pickup_Time'] = pd.to_datetime(amazon_df['Pickup_Time'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "\n",
    "# using error = 'coerce' will convert invalid values, such as \"NaN \", into a special \"Not a Time\" (NaT) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the corrdinate values for insconsistencies\n",
    "amazon_df['Store_Latitude'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df['Store_Longitude'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of Negative Values in column 'Store Longitude':- \",len(amazon_df[amazon_df['Store_Longitude'] < 0]))\n",
    "print(\"Count of Negative Values in column 'Store Latitude':-\",len(amazon_df[amazon_df['Store_Latitude'] < 0]))\n",
    "print(\"Count of Negative Values in column 'Drop Latitude':-\",len(amazon_df[amazon_df['Drop_Latitude'] < 0]))\n",
    "print(\"Count of Negative Values in column 'Drop Longitude':-\",len(amazon_df[amazon_df['Drop_Longitude'] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the corrdinates as they seems to be noisy\n",
    "\n",
    "# Valid Indian Corrdinate ranges\n",
    "lat_min, lat_max = 8.0, 37.0\n",
    "long_min, long_max = 68.0, 97.0\n",
    "\n",
    "# Mask Invalid Stores\n",
    "valid_store = amazon_df[\n",
    "               (amazon_df['Store_Latitude'].between(lat_min,lat_max)) &\n",
    "               (amazon_df['Store_Longitude'].between(long_min,long_max))\n",
    "             ]\n",
    "\n",
    "# Mask Invalid drop locations\n",
    "valid_store = amazon_df[\n",
    "               (amazon_df['Drop_Latitude'].between(lat_min,lat_max)) &\n",
    "               (amazon_df['Drop_Longitude'].between(long_min,long_max))\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the map of all coordinates\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Combine store + drop coordinates\n",
    "coords = amazon_df[['Store_Latitude','Store_Longitude']].values.tolist() + \\\n",
    "         amazon_df[['Drop_Latitude','Drop_Longitude']].values.tolist()\n",
    "\n",
    "# Base map centered on India\n",
    "map_heat = folium.Map(location=[20.5937, 78.9629], zoom_start=4, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Add heatmap layer\n",
    "HeatMap(coords, radius=5, blur=4, min_opacity=0.4).add_to(map_heat)\n",
    "\n",
    "# Display directly in Jupyter\n",
    "map_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed data into a new csv file\n",
    "amazon_df.to_csv(\"../dataset/processed_delievery_data.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSa1f5Uengrz"
   },
   "source": [
    "### What all manipulations have you done and insights you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbyXE7I1olp8"
   },
   "source": [
    "### Key Points\n",
    "1) Missing Values in the \"Agent_Rating\" Column were imputed with the median to avoid skewness in the data. The col also contained ratings as 6.0 so those were capped to 5.\n",
    "2) Missing Values in the \"Weather\" Column were imputed with the Mode, as it's a categorical column.\n",
    "3) Coordinates contained negative values that will make it noisy so they were capped with indian coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF8Ens_Soomf"
   },
   "source": [
    "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and use both the dataset for visualization \n",
    "df = pd.read_csv(\"../dataset/processed_delievery_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wOQAZs5pc--"
   },
   "source": [
    "#### Chart - 1 Histogram for Analysis of Delivery Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v_ESjsspbW7"
   },
   "outputs": [],
   "source": [
    "# Chart - 1 visualization code\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.histplot(df['Delivery_Time'], bins=50, kde = True, color = 'darkorange')\n",
    "plt.title(\"Distribution of Delivery Time(in hours)\", fontsize = 16)\n",
    "plt.xlabel(\"Delivery Time (hours)\", fontsize=12)\n",
    "plt.ylabel(\"Count\",fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig(\"../visualizations/delivery_time_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5QZ13OEpz2H"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XESiWehPqBRc"
   },
   "source": [
    "A histogram is an excellent tool for understanding the overall shape of your data. It helps to summarize a dataset by showing the frequency of data points within a series of intervals, or \"bins\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ7QKXXCp7Bj"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_j1G7yiqdRP"
   },
   "source": [
    "- Multimodal distribution with a major spike around 140 hours.\n",
    "- Suggests a common delivery timeframe across many orders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "448CDAPjqfQr"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cspy4FjqxJW"
   },
   "source": [
    "-  Not shown here, but variability suggests other factors (like traffic/weather) play a role.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSlN3yHqYklG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Chart - 2 Box Plot of Delivery Time Analysis for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4YgtaqtYklH"
   },
   "outputs": [],
   "source": [
    "# Chart - 2 visualization code\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.boxplot(df['Delivery_Time'], color = 'darkorange')\n",
    "plt.title(\"Box Plot of Delivery Time(in hours)\", fontsize = 16)\n",
    "plt.xlabel(\"Delivery Time (hours)\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig(\"../visualizations/box_plot_delivery_time.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6dVpIINYklI"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aaW0BYyYklI"
   },
   "source": [
    "Box plots are good at quickly visualizing the distribution of numerical data, allowing for comparisons between multiple groups by showing central tendency (median), spread (quartiles), symmetry, and outliers all at a glance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijmpgYnKYklI"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSx9atu2YklI"
   },
   "source": [
    "- Median delivery time is around ~130 hours.\n",
    "- There’s one clear outlier above the upper whisker, indicating an unusually long delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JiQyfWJYklI"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcBbebzrYklV"
   },
   "source": [
    "- Not shown here, but variability suggests other factors (like traffic/weather) play a role.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM7whBJCYoAo"
   },
   "source": [
    "#### Chart - 3 Plotting Map for Geographical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6GMdE67YoAp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chart - 3 visualization code\n",
    "m = folium.Map(location=[20.5937, 78.9629], zoom_start=5, tiles='cartodb dark_matter')\n",
    "\n",
    "store_points = df[['Store_Latitude', 'Store_Longitude']].dropna().values.tolist()\n",
    "drop_points  = df[['Drop_Latitude', 'Drop_Longitude']].dropna().values.tolist()\n",
    "\n",
    "HeatMap(store_points, radius=6, blur=4, name=\"Stores\").add_to(m)\n",
    "HeatMap(drop_points, radius=6, blur=4, name=\"Drops\").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fge-S5ZAYoAp"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dBItgRVYoAp"
   },
   "source": [
    "Maps are good for considering the larger picture especially for the case when latitude and longitude are given. As out data has Delivery Store and pickup locations so it's best to plot the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85gYPyotYoAp"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jstXR6OYoAp"
   },
   "source": [
    "- The central cluster of brightly colored dots (blue, green, yellow) arranged symmetrically suggests a dense concentration of activity in a specific region.\n",
    "- The mirrored reflection below the cluster implies a balanced or duplicated distribution, possibly across a natural divider like a river, highway, or city boundary.\n",
    "- The density of dots likely corresponds to high delivery volume or agent activity in that region.\n",
    "- If each dot represents a delivery or agent location, the central area is clearly a hotspot — possibly an urban center or logistics hub.\n",
    "- Sparse or absent dots in outer areas may indicate low coverage, longer delivery times, or fewer agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoGjAbkUYoAp"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfJ8IqMcYoAp"
   },
   "source": [
    "- You could use this map to optimize agent placement, adjust delivery zones, or target underserved areas for improvement.\n",
    "- If this is part of a larger dataset, overlaying delivery time or agent rating could reveal performance hotspots vs bottlenecks.\n",
    "\n",
    "- Regions with fewer or scattered dots may suffer from delays, longer routes, or lower agent density.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Of9eVA-YrdM"
   },
   "source": [
    "#### Chart - 4 Histogram for Agent Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irlUoxc8YrdO"
   },
   "outputs": [],
   "source": [
    "# Chart - 4 visualization code\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['Agent_Rating'], bins=20, color=\"darkorange\", kde=False)\n",
    "plt.title(\"Distribution of Agent Ratings\", fontsize=16)\n",
    "plt.xlabel(\"Agent Rating\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.savefig(\"../visualizations/distribution_agent_ratings.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iky9q4vBYrdO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJRCwT6DYrdO"
   },
   "source": [
    "A histogram is an excellent tool for understanding the overall shape of your data. It helps to summarize a dataset by showing the frequency of data points within a series of intervals, or \"bins\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6T5p64dYrdO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx8WAJvtYrdO"
   },
   "source": [
    "- Most agents are rated 4.0–5.0, with a peak at 5.0.\n",
    "- Very few agents fall below 4.0, indicating generally strong performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Ehk30pYrdP"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLNxxz7MYrdP"
   },
   "source": [
    "- Yes, it shows the agents are performing well enough.\n",
    "- Directly as per the data no negative impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bamQiAODYuh1"
   },
   "source": [
    "#### Chart - 5 Box Plot View for Delivery Time vs. Agent Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIJwrbroYuh3"
   },
   "outputs": [],
   "source": [
    "# Chart - 5 visualization code\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Agent_Rating', y='Delivery_Time', data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Delivery Time vs. Agent Rating\", fontsize=16)\n",
    "plt.xlabel(\"Agent Rating\", fontsize=12)\n",
    "plt.ylabel(\"Delivery Time (hours)\", fontsize=12)\n",
    "plt.savefig(\"../visualizations/delivery_time_vs_agent_rating.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHF8YVU7Yuh3"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcxuIMRPYuh3"
   },
   "source": [
    "Box plots are good at quickly visualizing the distribution of numerical data, allowing for comparisons between multiple groups by showing central tendency (median), spread (quartiles), symmetry, and outliers all at a glance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwzvFGzlYuh3"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyqkiB8YYuh3"
   },
   "source": [
    "- Agents with higher ratings (4.5–5.0) have lower and more consistent delivery times.\n",
    "- Lower-rated agents show more variability and longer delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYpmQ266Yuh3"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WtzZ_hCYuh4"
   },
   "source": [
    "- Clear inverse relationship: better ratings → faster delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH-pJp9IphqM"
   },
   "source": [
    "#### Chart - 6 Bar Plot for Weather Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuRf4wtuphqN"
   },
   "outputs": [],
   "source": [
    "# Chart - 6 visualization code\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Weather', y='Delivery_Time', data=df, estimator=\"mean\", palette=\"viridis\")\n",
    "plt.title(\"Average Delivery Time by Weather Condition\", fontsize=16)\n",
    "plt.xlabel(\"Weather\", fontsize=12)\n",
    "plt.ylabel(\"Average Delivery Time (hours)\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"../visualizations/average_delivery_time_by_weather_condition.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbFf2-_FphqN"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loh7H2nzphqN"
   },
   "source": [
    "Barplots are effective for presenting simple comparisons, like sales data or survey results, because the height of each bar intuitively represents a category's quantity or value, allowing for quick understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ouA3fa0phqN"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VECbqPI7phqN"
   },
   "source": [
    "- Yes. Fog (Approx. 135 hrs) and Cloudy (Approx. 130 hrs) cause the longest delays.\n",
    "- Sunny weather (Approx. 110 hrs) allows faster deliveries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Seke61FWphqN"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW4_bGpfphqN"
   },
   "source": [
    "- Poor visibility (Fog, Cloudy) correlates with slower delivery.\n",
    "- Windy and Snowstorms also show moderate delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIIx-8_IphqN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Chart - 7 Barplot for Average Delivery Time Analysis by Traffic Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqAIGUfyphqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 7 visualization code\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Traffic', y='Delivery_Time', data=df, estimator='mean', palette=\"coolwarm\")\n",
    "plt.title(\"Average Delivery Time by Traffic Condition\", fontsize=16)\n",
    "plt.xlabel(\"Traffic Condition\", fontsize=12)\n",
    "plt.ylabel(\"Average Delivery Time (hours)\", fontsize=12)\n",
    "plt.savefig(\"../visualizations/average_delivery_time_by_traffic_condition.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t27r6nlMphqO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv6ro40sphqO"
   },
   "source": [
    "Barplots are effective for presenting simple comparisons, like sales data or survey results, because the height of each bar intuitively represents a category's quantity or value, allowing for quick understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2jJGEOYphqO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po6ZPi4hphqO"
   },
   "source": [
    "- Definitely. \"Jam\" and \"High\" traffic conditions lead to the longest delivery times (~125–140 hours).\n",
    "- \"Low\" traffic shows the shortest (~100 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0JNsNcRphqO"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvSq8iUTphqO"
   },
   "source": [
    "- Delivery time increases with traffic congestion.\n",
    "- \"NaN\" (missing data) still shows ~125 hours, which may mask hidden inefficiencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZR9WyysphqO"
   },
   "source": [
    "#### Chart - 8 Bar Plot for Product Category vs. Delivery Time Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdPTWpAVphqO"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Category', y='Delivery_Time', data=df, estimator='mean', palette=\"viridis\")\n",
    "plt.title(\"Average Delivery Time by Product Category\", fontsize=16)\n",
    "plt.xlabel(\"Product Category\", fontsize=12)\n",
    "plt.ylabel(\"Average Delivery Time (hours)\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"../visualizations/average_delivery_time_by_product_category.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCFgpxoyphqP"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVxDimi2phqP"
   },
   "source": [
    "Barplots are effective for presenting simple comparisons, like sales data or survey results, because the height of each bar intuitively represents a category's quantity or value, allowing for quick understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVtJsKN_phqQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngGi97qjphqQ"
   },
   "source": [
    "- Most categories cluster around ~130 hours.\n",
    "- Grocery stands out with a much faster delivery time (~20 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lssrdh5qphqQ"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBpY5ekJphqQ"
   },
   "source": [
    "- Yes. Grocery is delivered significantly faster, likely due to perishability or priority logistics.\n",
    "- Not directly visible here, but Grocery’s efficiency suggests better agent performance or optimized routes in that category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLjJCtPM0KBk"
   },
   "source": [
    "## ***5. Feature Engineering & Data Pre-processing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Time-based features**\n",
    "    - order_hour, order_day, order_weekday (customer ordering behavior)\n",
    "    - pickup_hour, pickup_day, pickup_weekday\n",
    "    - time_to_pickup = Pickup_Time − Order_Time\n",
    "    - delivery_duration (if Delivery_Time column exists or can be derived)\n",
    "    - Flags like is_weekend, is_peak_hour\n",
    "2. **Geographic features**\n",
    "    - Calculate haversine distance between store and delivery location using lat/long\n",
    "    - Cluster areas (urban vs rural delivery zones)\n",
    "3. **Traffic & Weather interactions**\n",
    "    - Encode Weather and Traffic into categories/numbers\n",
    "    - Create interactions like traffic_level × distance\n",
    "4. **Customer / Agent behavior**\n",
    "    - Average rating per agent (historical performance)\n",
    "    - Total orders per customer (loyalty proxy)\n",
    "5. **Categorical Encodings**\n",
    "    - One-hot encoding for Weather, Vehicle_Type, Traffic\n",
    "6. **Outlier treatment**\n",
    "    - Cap extreme delivery times, distances, or times-to-pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset again for feature enginnering\n",
    "df = pd.read_csv(\"../dataset/processed_delievery_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiyOF9F70UgQ"
   },
   "source": [
    "### 1. Creating Time Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRsAHk1K0fpS"
   },
   "outputs": [],
   "source": [
    "# convert date/time columns\n",
    "df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
    "df['Order_Time'] = pd.to_datetime(df['Order_Time'], format = \"%H:%M:%S\", errors='coerce').dt.time\n",
    "df['Pickup_Time'] = pd.to_datetime(df['Pickup_Time'], format = \"%H:%M:%S\", errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine date+time into full date-time objects\n",
    "df['Order_Datetime'] = pd.to_datetime(df['Order_Date'].dt.strftime(\"%Y-%m-%d\").astype(str) + \" \" + df['Order_Time'].astype(str), errors='coerce')\n",
    "df['Pickup_Datetime'] = pd.to_datetime(df['Order_Date'].dt.strftime(\"%Y-%m-%d\").astype(str) + \" \" + df['Pickup_Time'].astype(str), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Order_Datetime'].isna().sum())\n",
    "print(df['Pickup_Datetime'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where \"Order_DateTime\" or \"Pickup_DateTime\" couldn’t be created.\n",
    "df = df.dropna(subset=['Order_Datetime','Pickup_Datetime']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for na values\n",
    "print(df['Order_Datetime'].isna().sum())\n",
    "print(df['Pickup_Datetime'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: order time features\n",
    "df['Order_Hour'] = df['Order_Datetime'].dt.hour\n",
    "df['Order_Day'] = df['Order_Datetime'].dt.day_name()\n",
    "df['Order_Weekday'] = df['Order_Datetime'].dt.weekday\n",
    "df['Is_Weekend'] = df['Order_Weekday'].apply(lambda x:1 if x >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Pickup time features\n",
    "df['Pickup_Hour'] = df['Pickup_Datetime'].dt.hour\n",
    "df['Pickup_Day'] = df['Pickup_Datetime'].dt.day\n",
    "df['Pickup_Weekday'] = df['Pickup_Datetime'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time gap between order and pickup time (in minutes)\n",
    "df['Time_to_Pickup'] = (df['Pickup_Datetime'] - df['Order_Datetime']).dt.total_seconds() / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order_Day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders_per_day\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.countplot(x = 'Order_Day', data= df, order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], color=\"darkorange\")\n",
    "plt.title(\"Orders Distribution by Day of the Week\", fontsize = 16)\n",
    "plt.xlabel(\"Day of Week\", fontsize = 12)\n",
    "plt.ylabel(\"Number of Orders\", fontsize = 12)\n",
    "plt.savefig(\"../visualizations/order_distribution_by_weekday.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The CountPlot is used to visualize the frequency or count of observations within each category of a single categorical variable.\n",
    "\n",
    "2) The following plot reveals:- \n",
    "- Wednesday and Friday are busiest.\n",
    "- Saturday sees the fewest orders.\n",
    "- but high-volume days may strain logistics, affecting delivery speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders_per_hour\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.countplot(x = 'Order_Hour', data= df, color=\"darkorange\")\n",
    "plt.title(\"Orders Distribution by Hour of the Day\", fontsize = 16)\n",
    "plt.xlabel(\"Hour of th Day\", fontsize = 12)\n",
    "plt.ylabel(\"Number of Orders\", fontsize = 12)\n",
    "plt.savefig(\"../visualizations/order_distribution_by_hour_day.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The CountPlot is used to visualize the frequency or count of observations within each category of a single categorical variable.\n",
    "\n",
    "2) The following plot reveals:- \n",
    "- Peak ordering hours: 8–11 AM and 18–22 PM.\n",
    "- Early morning (0–7) and midday (12–15) are quieter.\n",
    "- But peak ordering hours often align with longer delivery times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wuGOrhz0itI"
   },
   "source": [
    "#### What all missing value imputation techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ixusLtI0pqI"
   },
   "source": [
    "***We handled missing values using:***\n",
    "- Numerical Features: Imputed using median to avoid skewness from extreme values (e.g., Agent Age, Agent Rating).\n",
    "- Categorical Features: Imputed using mode (most frequent category) for features like Weather, Traffic, and Vehicle type.\n",
    "\n",
    "***Why:*** Median and mode are robust against outliers and preserve the central tendency of the data without artificially inflating variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id1riN9m0vUs"
   },
   "source": [
    "### 2. Creating Geographical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6w2CzZf04JK"
   },
   "outputs": [],
   "source": [
    "# Create Geographic Features\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance (km) between two points\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2) ** 2  + cos(lat1) * cos(lat2) * sin(dlon/2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371   # Earth Radius in KM\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Distance_KM'] = df.apply(\n",
    "    lambda row: haversine(row['Store_Latitude'], row['Store_Longitude'],\n",
    "                          row['Drop_Latitude'], row['Drop_Longitude']), \n",
    "                          axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Distance_KM', y='Delivery_Time', data=df, alpha=0.5, color=\"darkorange\")\n",
    "sns.regplot(x='Distance_KM', y='Delivery_Time', data=df, scatter=False, color=\"blue\")\n",
    "plt.title(\"Distance vs Delivery Time\", fontsize=16)\n",
    "plt.xlabel(\"Distance (km)\", fontsize=12)\n",
    "plt.ylabel(\"Delivery Time (hours)\", fontsize=12)\n",
    "plt.savefig(\"../visualizations/distance_vs_delivery_time.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "578E2V7j08f6"
   },
   "source": [
    "##### What all Geographical Features have you created and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGZz5OrT1HH-"
   },
   "source": [
    "#### We engineered ***Haversine Distance*** between store (pickup) and customer (drop) latitude/longitude.\n",
    "\n",
    "***Why:*** Distance is a core driver of delivery time. Haversine accounts for curvature of the Earth, making it more realistic than Euclidean distance. This improved the model’s understanding of geographical spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89xtkJwZ18nB"
   },
   "source": [
    "### 3. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21JmIYMG2hEo"
   },
   "outputs": [],
   "source": [
    "# Encode your categorical columns\n",
    "df = pd.get_dummies(df, columns = ['Weather', 'Traffic', 'Vehicle', 'Area', 'Category', 'Order_Day'], drop_first = True) \n",
    "# now check the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "corr = df[['Delivery_Time', 'Agent_Rating', 'Distance_KM']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\", fontsize=16)\n",
    "plt.savefig(\"../visualizations/correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67NQN5KX2AMe"
   },
   "source": [
    "#### What all categorical encoding techniques have you used & why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDaue5h32n_G"
   },
   "source": [
    "#### We applied One-Hot Encoding on categorical features such as Weather, Traffic, Vehicle, Area, Category.\n",
    "\n",
    "***Why:***\n",
    "- These variables are nominal (no inherent ranking).\n",
    "- Using Label Encoding would have implied ordinal relationships (e.g., Sunny > Rainy), which would mislead tree-based models.\n",
    "- One-Hot Encoding ensures each category gets its own binary feature, preventing ordinal bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oLEiFgy-5Pf"
   },
   "source": [
    "### 4. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DejudWSA-a0"
   },
   "source": [
    "#### 1. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLhe8UmaBCEE"
   },
   "outputs": [],
   "source": [
    "# Select your features wisely to avoid overfitting\n",
    "col_drop_for_ml = ['Order_ID','Order_Date','Order_Time','Pickup_Time','Order_Datetime', 'Pickup_Datetime']\n",
    "df_ml = df.drop(columns = col_drop_for_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names (important for LightGBM/XGBoost)\n",
    "df_ml.columns = df_ml.columns.str.replace(\" \", \"_\").str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEMng2IbBLp7"
   },
   "source": [
    "##### What all feature selection methods have you used  and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb2Lh6Z8BgGs"
   },
   "source": [
    "#### Feature Importance from Tree-Based Models (Random Forest, LightGBM) was used.\n",
    "\n",
    "***Why:*** \n",
    "- These models inherently provide importance scores that reflect how much each feature contributes to reducing prediction error.\n",
    "- Instead of dropping low-importance features early, we retained them for experimentation and let model training + MLflow experiments show which mattered most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAdphbQ9Bhjc"
   },
   "source": [
    "##### Which all features you found important and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGgaEstsBnaf"
   },
   "source": [
    "From the prior EDA Analysis we found following features to be useful:\n",
    "\n",
    "- Category_Grocery → Higher variance in delivery times due to perishable nature and demand.\n",
    "- Agent Rating → Indicates delivery efficiency & reliability.\n",
    "- Distance_KM → Longer distances lead to longer delivery times.\n",
    "- Traffic_Low / Medium → Captures delivery delays due to road congestion.\n",
    "- Agent Age → Proxy for experience and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhH2vgX9EjGr"
   },
   "source": [
    "### 8. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CTyd2UwEyNM"
   },
   "outputs": [],
   "source": [
    "# Define Features & Target\n",
    "X = df_ml.drop(columns=[\"Delivery_Time\"])  # features\n",
    "y = df_ml[\"Delivery_Time\"]                 # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data to train and test. Choose Splitting ratio wisely.\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjKvONjwE8ra"
   },
   "source": [
    "##### What data splitting ratio have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2lJ8cobFDb_"
   },
   "source": [
    "#### 80:20 split → 80% training, 20% testing.\n",
    "\n",
    "***Why:***\n",
    "\n",
    "- Sufficient data for training complex models.\n",
    "- Enough test data to validate generalization.\n",
    "- Standard practice for balanced medium-sized datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFOzZv6IFROw"
   },
   "source": [
    "##### Do you think the dataset is imbalanced? Explain Why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeKDIv7pFgcC"
   },
   "source": [
    "- The dataset is not a classification dataset → It’s a regression problem (continuous target: delivery time).Hence, imbalance is not applicable. Instead, the main challenge is target variance (some deliveries take very long, others very short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfCC591jGiD4"
   },
   "source": [
    "## ***6. ML Model Implementation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries for ML Modelling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB4l2ZhMeS1U"
   },
   "source": [
    "### ML Model used for Training:- \n",
    "#### 1. Linear Regression\n",
    "#### 2. Decision Tree\n",
    "#### 3. Random Forest\n",
    "#### 4. Gradient Boosting\n",
    "#### 5. XGBoost\n",
    "#### 6. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ebyywQieS1U"
   },
   "outputs": [],
   "source": [
    "# ML Model Implementation\n",
    "# Define Models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train & Evaluate Models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "        results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R²\": r2}\n",
    "        print(f\"{name} trained successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name} failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArJBuiUVfxKd"
   },
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model: LightGBM\n",
    "\n",
    "Metrics:\n",
    "\n",
    "- MAE (Mean Absolute Error): ~17.12\n",
    "\n",
    "- RMSE (Root Mean Squared Error): ~22.10\n",
    "\n",
    "- R² Score: ~0.82\n",
    "\n",
    "***Why chosen:*** Captures non-linear patterns, handles categorical features well after encoding, fast training, and robust performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqD5ZohzfxKe"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart\n",
    "# Plot Model Performance\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=results_df.index, y=results_df[\"R²\"])\n",
    "plt.title(\"Model Comparison (R² Score)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (for best model, e.g. Random Forest)\n",
    "best_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_\n",
    "feat_imp = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=feat_imp.head(15))\n",
    "plt.title(\"Top 15 Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qY1EAkEfxKe"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning for Top Performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary Libraries\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Space\n",
    "param_dict = {\n",
    "    'num_leaves': [31, 50, 70, 100],\n",
    "    'max_depth': [-1, 10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 300, 500, 1000],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    lgb_model, \n",
    "    param_distributions=param_dict,\n",
    "    n_iter=30,  # number of random combinations\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dy61ujd6fxKe"
   },
   "outputs": [],
   "source": [
    "%time\n",
    "random_search.fit(X_train, y_train)\n",
    "# ML Model Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best RMSE Score:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_lgb = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = best_lgb.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Tuned LightGBM Performance -> MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiV4Ypx8fxKe"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "negyGRa7fxKf"
   },
   "source": [
    "- Used GridSearchCV / RandomizedSearchCV (depending on models).\n",
    "\n",
    "- Tuned parameters: learning rate, max depth, num leaves, n_estimators, subsample, colsample_bytree.\n",
    "\n",
    "***Why:*** These hyperparameters heavily influence model complexity and performance. Hyperparameter tuning improved generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfvqoZmBfxKf"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaLui8CcfxKf"
   },
   "source": [
    "Yes.\n",
    "\n",
    " - Before tuning: RMSE ~25.3, MAE ~19.5, R² ~0.76\n",
    "\n",
    "- After tuning (LightGBM): RMSE ~22.1, MAE ~17.1, R² ~0.82\n",
    "\n",
    "Improvement came from better control of learning rate, depth, and leaves → reduced overfitting and improved test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_CCil-SKHpo"
   },
   "source": [
    "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHVz9hHDKFms"
   },
   "source": [
    "- MAE: Easy to interpret (average minutes off prediction). Directly maps to customer expectation mismatch.\n",
    "\n",
    "- RMSE: Penalizes larger errors, useful since extreme delays hurt customer trust.\n",
    "\n",
    "- R²: Overall goodness-of-fit, shows how much variance is explained.\n",
    "\n",
    "***Why:*** A combination ensures we capture both customer-level precision (MAE) and operational risk (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBFFvTBNJzUa"
   },
   "source": [
    "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ksF5Q1LKTVm"
   },
   "source": [
    "#### Final Model: LightGBM\n",
    "\n",
    "***Why:***\n",
    "\n",
    "- Best trade-off between accuracy (lowest MAE, RMSE, highest R²).\n",
    "\n",
    "- Handles non-linear data efficiently.\n",
    "\n",
    "- Scales well for large datasets.\n",
    "\n",
    "- Outperformed XGBoost and Random Forest in our MLflow experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvGl1hHyA_VK"
   },
   "source": [
    "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnvVTiIxBL-C"
   },
   "source": [
    "#### Model: LightGBM Regressor\n",
    "\n",
    "- Used ***feature importance*** plot to analyze drivers.\n",
    "\n",
    " - Top features: Category_Grocery, Distance_KM, Agent Rating, Traffic_Low, Agent Age.\n",
    "\n",
    "***Explainability:*** These align with domain knowledge → groceries & traffic directly affect delivery time, while agent quality affects reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyNgTHvd2WFk"
   },
   "source": [
    "## ***7.*** ***Track Models on MLFlow***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load Processed Data (ML version, not BI one)\n",
    "df_ml = pd.read_csv(\"../dataset/ml__amazon_delievery_dataset.csv\")\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Clean column names (important for LightGBM/XGBoost)\n",
    "df_ml.columns = df_ml.columns.str.replace(\" \", \"_\").str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define Features & Target\n",
    "X = df_ml.drop(columns=[\"Delivery_Time\"])  # features\n",
    "y = df_ml[\"Delivery_Time\"]                 # target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dictionary of models (already defined earlier in your code)\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results = {}\n",
    "\n",
    "mlflow.set_experiment(\"Amazon_Delivery_Time_Prediction\")  # Create/use an MLflow experiment\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R²\": r2}\n",
    "\n",
    "        # Log params (basic ones only, you can add more if tuned)\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, name=\"model\")\n",
    "\n",
    "        print(f\"{name} logged successfully → RMSE={rmse:.4f}\")\n",
    "\n",
    "print(\"All models logged into MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyNgTHvd2WFk"
   },
   "source": [
    "## ***8.*** ***Main Streamlit App for Prediction and Deployment at Streamlit Cloud***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "import joblib\n",
    "\n",
    "# Load the best model from MLflow (replace with actual run_id/model name if needed)\n",
    "\n",
    "#logged_model = \"runs:/47f8cd46b3bb45f2b2f0333deeb6ee80/model\"\n",
    "#model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "model = joblib.load(\"../code_files/saved_models/model.pkl\")\n",
    "\n",
    "feature_columns = [\n",
    "    'Agent_Age', 'Agent_Rating', 'Store_Latitude', 'Store_Longitude',\n",
    "    'Drop_Latitude', 'Drop_Longitude', 'Order_Hour', 'Order_Day',\n",
    "    'Order_Weekday', 'Is_Weekend', 'Pickup_Hour', 'Pickup_Day',\n",
    "    'Pickup_Weekday', 'Time_to_Pickup', 'Distance_KM', 'Weather_Fog',\n",
    "    'Weather_Sandstorms', 'Weather_Stormy', 'Weather_Sunny',\n",
    "    'Weather_Windy', 'Traffic_Jam_', 'Traffic_Low_', 'Traffic_Medium_',\n",
    "    'Vehicle_scooter_', 'Vehicle_van', 'Area_Other', 'Area_Semi_Urban_',\n",
    "    'Area_Urban_', 'Category_Books', 'Category_Clothing',\n",
    "    'Category_Cosmetics', 'Category_Electronics', 'Category_Grocery',\n",
    "    'Category_Home', 'Category_Jewelry', 'Category_Kitchen',\n",
    "    'Category_Outdoors', 'Category_Pet_Supplies', 'Category_Shoes',\n",
    "    'Category_Skincare', 'Category_Snacks', 'Category_Sports',\n",
    "    'Category_Toys'\n",
    "]\n",
    "\n",
    "def preprocess_user_input(user_input: dict):\n",
    "    df_input = pd.DataFrame([user_input])\n",
    "    df_input = pd.get_dummies(df_input, columns=['Weather','Traffic','Vehicle','Area','Category'])\n",
    "    df_input = df_input.reindex(columns=feature_columns, fill_value=0)\n",
    "    return df_input\n",
    "\n",
    "st.title(\"🚚 Delivery Time Predictor\")\n",
    "\n",
    "# --- User Inputs (only important ones) ---\n",
    "category = st.selectbox(\"Category\", [\"Books\",\"Clothing\",\"Cosmetics\",\"Electronics\",\"Grocery\",\n",
    "                                     \"Home\",\"Jewelry\",\"Kitchen\",\"Outdoors\",\"Pet_Supplies\",\n",
    "                                     \"Shoes\",\"Skincare\",\"Snacks\",\"Sports\",\"Toys\"])\n",
    "\n",
    "agent_rating = st.slider(\"Agent Rating\", 1.0, 5.0, 4.5)\n",
    "agent_age = st.slider(\"Agent Age\", 18, 65, 30)\n",
    "distance_km = st.number_input(\"Distance (KM)\", 0.0, 50.0, 5.0)\n",
    "traffic = st.selectbox(\"Traffic\", [\"Jam_\", \"Low_\", \"Medium_\"])\n",
    "weather = st.selectbox(\"Weather\", [\"Fog\",\"Sandstorms\",\"Stormy\",\"Sunny\",\"Windy\"])\n",
    "\n",
    "# --- Defaults for less important columns ---\n",
    "user_input = {\n",
    "    \"Agent_Age\": agent_age,\n",
    "    \"Agent_Rating\": agent_rating,\n",
    "    \"Distance_KM\": distance_km,\n",
    "    \"Weather\": weather,\n",
    "    \"Traffic\": traffic,\n",
    "    \"Category\": category,\n",
    "    \"Vehicle\": \"scooter_\",   # default\n",
    "    \"Area\": \"Urban_\",        # default\n",
    "    \"Store_Latitude\": 12.97, # default\n",
    "    \"Store_Longitude\": 77.59,\n",
    "    \"Drop_Latitude\": 12.98,\n",
    "    \"Drop_Longitude\": 77.60,\n",
    "    \"Order_Hour\": 14,\n",
    "    \"Order_Day\": 15,\n",
    "    \"Order_Weekday\": 2,\n",
    "    \"Is_Weekend\": 0,\n",
    "    \"Pickup_Hour\": 15,\n",
    "    \"Pickup_Day\": 15,\n",
    "    \"Pickup_Weekday\": 2,\n",
    "    \"Time_to_Pickup\": 10\n",
    "}\n",
    "\n",
    "# --- Preprocess & Predict ---\n",
    "df_input = preprocess_user_input(user_input)\n",
    "\n",
    "if st.button(\"Predict Delivery Time\"):\n",
    "    prediction = model.predict(df_input)[0]\n",
    "    st.success(f\"⏱ Estimated Delivery Time: {prediction:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyNgTHvd2WFk"
   },
   "source": [
    "## ***9.*** ***Future Work (Optional)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Better Encoding:** Replace one-hot encoding with embeddings or target encoding for categories with many levels (e.g., product categories).\n",
    "2. **Real-Time Data:** Integrate live traffic and weather APIs for more accurate predictions.\n",
    "3. **MLOps Pipeline:** Deploy MLflow on cloud (AWS/GCP) for remote model registry & CI/CD.\n",
    "4. **Advanced Models:** Try deep learning (RNNs for time-sequence features, TabNet for tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Kee-DAl2viO"
   },
   "source": [
    "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCX9965dhzqZ"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjb1IsQkh3yE"
   },
   "source": [
    "This project successfully implemented an end-to-end ML pipeline for Amazon delivery time prediction. Starting from data cleaning, feature engineering (including haversine distance), and one-hot encoding, we trained multiple ML models and tracked them using MLflow. Hyperparameter-tuned LightGBM emerged as the best model with R² ≈ 0.82. A Streamlit app was developed for interactive predictions, bridging the gap between model and user experience. This solution reflects real-world MLOps practices, emphasizes interpretability, and demonstrates strong potential for deployment at scale to optimize delivery operations and improve customer satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIfDvo9L0UH2"
   },
   "source": [
    "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vncDsAP0Gaoa",
    "FJNUwmbgGyua",
    "w6K7xa23Elo4",
    "yQaldy8SH6Dl",
    "mDgbUHAGgjLW",
    "O_i_v8NEhb9l",
    "HhfV-JJviCcP",
    "Y3lxredqlCYt",
    "3RnN4peoiCZX",
    "x71ZqKXriCWQ",
    "7hBIi_osiCS2",
    "JlHwYmJAmNHm",
    "35m5QtbWiB9F",
    "PoPl-ycgm1ru",
    "H0kj-8xxnORC",
    "nA9Y7ga8ng1Z",
    "PBTbrJXOngz2",
    "u3PMJOP6ngxN",
    "dauF4eBmngu3",
    "bKJF3rekwFvQ",
    "MSa1f5Uengrz",
    "GF8Ens_Soomf",
    "0wOQAZs5pc--",
    "K5QZ13OEpz2H",
    "lQ7QKXXCp7Bj",
    "448CDAPjqfQr",
    "KSlN3yHqYklG",
    "t6dVpIINYklI",
    "ijmpgYnKYklI",
    "-JiQyfWJYklI",
    "EM7whBJCYoAo",
    "fge-S5ZAYoAp",
    "85gYPyotYoAp",
    "RoGjAbkUYoAp",
    "4Of9eVA-YrdM",
    "iky9q4vBYrdO",
    "F6T5p64dYrdO",
    "y-Ehk30pYrdP",
    "bamQiAODYuh1",
    "QHF8YVU7Yuh3",
    "GwzvFGzlYuh3",
    "qYpmQ266Yuh3",
    "OH-pJp9IphqM",
    "bbFf2-_FphqN",
    "_ouA3fa0phqN",
    "Seke61FWphqN",
    "PIIx-8_IphqN",
    "t27r6nlMphqO",
    "r2jJGEOYphqO",
    "b0JNsNcRphqO",
    "BZR9WyysphqO",
    "jj7wYXLtphqO",
    "eZrbJ2SmphqO",
    "rFu4xreNphqO",
    "YJ55k-q6phqO",
    "gCFgpxoyphqP",
    "OVtJsKN_phqQ",
    "lssrdh5qphqQ",
    "U2RJ9gkRphqQ",
    "1M8mcRywphqQ",
    "tgIPom80phqQ",
    "JMzcOPDDphqR",
    "x-EpHcCOp1ci",
    "X_VqEhTip1ck",
    "8zGJKyg5p1ck",
    "PVzmfK_Ep1ck",
    "n3dbpmDWp1ck",
    "ylSl6qgtp1ck",
    "ZWILFDl5p1ck",
    "M7G43BXep1ck",
    "Ag9LCva-p1cl",
    "E6MkPsBcp1cl",
    "2cELzS2fp1cl",
    "3MPXvC8up1cl",
    "NC_X3p0fY2L0",
    "UV0SzAkaZNRQ",
    "YPEH6qLeZNRQ",
    "q29F0dvdveiT",
    "EXh0U9oCveiU",
    "22aHeOlLveiV",
    "g-ATYxFrGrvw",
    "Yfr_Vlr8HBkt",
    "8yEUt7NnHlrM",
    "tEA2Xm5dHt1r",
    "I79__PHVH19G",
    "Ou-I18pAyIpj",
    "fF3858GYyt-u",
    "4_0_7-oCpUZd",
    "hwyV_J3ipUZe",
    "3yB-zSqbpUZe",
    "dEUvejAfpUZe",
    "Fd15vwWVpUZf",
    "bn_IUdTipZyH",
    "49K5P_iCpZyH",
    "Nff-vKELpZyI",
    "kLW572S8pZyI",
    "dWbDXHzopZyI",
    "yLjJCtPM0KBk",
    "xiyOF9F70UgQ",
    "7wuGOrhz0itI",
    "id1riN9m0vUs",
    "578E2V7j08f6",
    "89xtkJwZ18nB",
    "67NQN5KX2AMe",
    "Iwf50b-R2tYG",
    "GMQiZwjn3iu7",
    "WVIkgGqN3qsr",
    "XkPnILGE3zoT",
    "Hlsf0x5436Go",
    "mT9DMSJo4nBL",
    "c49ITxTc407N",
    "OeJFEK0N496M",
    "9ExmJH0g5HBk",
    "cJNqERVU536h",
    "k5UmGsbsOxih",
    "T0VqWOYE6DLQ",
    "qBMux9mC6MCf",
    "-oLEiFgy-5Pf",
    "C74aWNz2AliB",
    "2DejudWSA-a0",
    "pEMng2IbBLp7",
    "rAdphbQ9Bhjc",
    "TNVZ9zx19K6k",
    "nqoHp30x9hH9",
    "rMDnDkt2B6du",
    "yiiVWRdJDDil",
    "1UUpS68QDMuG",
    "kexQrXU-DjzY",
    "T5CmagL3EC8N",
    "BhH2vgX9EjGr",
    "qjKvONjwE8ra",
    "P1XJ9OREExlT",
    "VFOzZv6IFROw",
    "TIqpNgepFxVj",
    "VfCC591jGiD4",
    "OB4l2ZhMeS1U",
    "ArJBuiUVfxKd",
    "4qY1EAkEfxKe",
    "PiV4Ypx8fxKe",
    "TfvqoZmBfxKf",
    "dJ2tPlVmpsJ0",
    "JWYfwnehpsJ1",
    "-jK_YjpMpsJ2",
    "HAih1iBOpsJ2",
    "zVGeBEFhpsJ2",
    "bmKjuQ-FpsJ3",
    "Fze-IPXLpx6K",
    "7AN1z2sKpx6M",
    "9PIHJqyupx6M",
    "_-qAgymDpx6N",
    "Z-hykwinpx6N",
    "h_CCil-SKHpo",
    "cBFFvTBNJzUa",
    "HvGl1hHyA_VK",
    "EyNgTHvd2WFk",
    "KH5McJBi2d8v",
    "iW_Lq9qf2h6X",
    "-Kee-DAl2viO",
    "gCX9965dhzqZ",
    "gIfDvo9L0UH2"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (amazon_delivery)",
   "language": "python",
   "name": "amazon_delivery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
